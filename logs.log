2021-09-02 14:40:32,916 [org.apache.spark.internal.Logging$class]-[ERROR] group.id is null, you should probably set it
2021-09-02 14:40:33,396 [org.apache.kafka.clients.consumer.internals.AbstractCoordinator$JoinGroupResponseHandler]-[ERROR] [Consumer clientId=consumer-1, groupId=] Attempt to join group failed due to fatal error: The configured groupId is invalid
2021-09-02 14:40:33,400 [org.apache.spark.internal.Logging$class]-[ERROR] Error starting the context, marking it as stopped
org.apache.kafka.common.errors.InvalidGroupIdException: The configured groupId is invalid
	at ... run in separate thread using org.apache.spark.util.ThreadUtils ... ()
	at org.apache.spark.streaming.StreamingContext.liftedTree1$1(StreamingContext.scala:578)
	at org.apache.spark.streaming.StreamingContext.start(StreamingContext.scala:572)
	at org.apache.spark.streaming.api.java.JavaStreamingContext.start(JavaStreamingContext.scala:556)
	at com.apple.streaming.upgrade.news.NewsRealtimeStatSpark.main(NewsRealtimeStatSpark.java:82)
2021-09-02 14:40:50,504 [org.apache.spark.internal.Logging$class]-[ERROR] group.id is null, you should probably set it
2021-09-02 14:40:50,880 [org.apache.kafka.clients.consumer.internals.AbstractCoordinator$JoinGroupResponseHandler]-[ERROR] [Consumer clientId=consumer-1, groupId=] Attempt to join group failed due to fatal error: The configured groupId is invalid
2021-09-02 14:40:50,883 [org.apache.spark.internal.Logging$class]-[ERROR] Error starting the context, marking it as stopped
org.apache.kafka.common.errors.InvalidGroupIdException: The configured groupId is invalid
	at ... run in separate thread using org.apache.spark.util.ThreadUtils ... ()
	at org.apache.spark.streaming.StreamingContext.liftedTree1$1(StreamingContext.scala:578)
	at org.apache.spark.streaming.StreamingContext.start(StreamingContext.scala:572)
	at org.apache.spark.streaming.api.java.JavaStreamingContext.start(JavaStreamingContext.scala:556)
	at com.apple.streaming.upgrade.news.NewsRealtimeStatSpark.main(NewsRealtimeStatSpark.java:82)
2021-09-02 14:44:59,641 [org.apache.spark.internal.Logging$class]-[ERROR] group.id is null, you should probably set it
2021-09-02 14:44:59,814 [org.apache.spark.internal.Logging$class]-[ERROR] Error starting the context, marking it as stopped
org.apache.kafka.common.config.ConfigException: Missing required configuration "key.deserializer" which has no default value.
	at org.apache.kafka.common.config.ConfigDef.parseValue(ConfigDef.java:472)
	at org.apache.kafka.common.config.ConfigDef.parse(ConfigDef.java:462)
	at org.apache.kafka.common.config.AbstractConfig.<init>(AbstractConfig.java:62)
	at org.apache.kafka.common.config.AbstractConfig.<init>(AbstractConfig.java:75)
	at org.apache.kafka.clients.consumer.ConsumerConfig.<init>(ConsumerConfig.java:499)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:615)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:596)
	at org.apache.spark.streaming.kafka010.Subscribe.onStart(ConsumerStrategy.scala:84)
	at org.apache.spark.streaming.kafka010.DirectKafkaInputDStream.consumer(DirectKafkaInputDStream.scala:73)
	at org.apache.spark.streaming.kafka010.DirectKafkaInputDStream.start(DirectKafkaInputDStream.scala:259)
	at org.apache.spark.streaming.DStreamGraph$$anonfun$start$7.apply(DStreamGraph.scala:54)
	at org.apache.spark.streaming.DStreamGraph$$anonfun$start$7.apply(DStreamGraph.scala:54)
	at scala.collection.parallel.mutable.ParArray$ParArrayIterator.foreach_quick(ParArray.scala:143)
	at scala.collection.parallel.mutable.ParArray$ParArrayIterator.foreach(ParArray.scala:136)
	at scala.collection.parallel.ParIterableLike$Foreach.leaf(ParIterableLike.scala:972)
	at scala.collection.parallel.Task$$anonfun$tryLeaf$1.apply$mcV$sp(Tasks.scala:49)
	at scala.collection.parallel.Task$$anonfun$tryLeaf$1.apply(Tasks.scala:48)
	at scala.collection.parallel.Task$$anonfun$tryLeaf$1.apply(Tasks.scala:48)
	at scala.collection.parallel.Task$class.tryLeaf(Tasks.scala:51)
	at scala.collection.parallel.ParIterableLike$Foreach.tryLeaf(ParIterableLike.scala:969)
	at scala.collection.parallel.AdaptiveWorkStealingTasks$WrappedTask$class.compute(Tasks.scala:152)
	at scala.collection.parallel.AdaptiveWorkStealingForkJoinTasks$WrappedTask.compute(Tasks.scala:443)
	at scala.concurrent.forkjoin.RecursiveAction.exec(RecursiveAction.java:160)
	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
	at ... run in separate thread using org.apache.spark.util.ThreadUtils ... ()
	at org.apache.spark.streaming.StreamingContext.liftedTree1$1(StreamingContext.scala:578)
	at org.apache.spark.streaming.StreamingContext.start(StreamingContext.scala:572)
	at org.apache.spark.streaming.api.java.JavaStreamingContext.start(JavaStreamingContext.scala:556)
	at com.apple.streaming.upgrade.news.NewsRealtimeStatSpark.main(NewsRealtimeStatSpark.java:82)
2021-09-02 14:45:24,372 [org.apache.spark.internal.Logging$class]-[ERROR] group.id is null, you should probably set it
2021-09-02 14:45:24,804 [org.apache.kafka.clients.consumer.internals.AbstractCoordinator$JoinGroupResponseHandler]-[ERROR] [Consumer clientId=consumer-1, groupId=] Attempt to join group failed due to fatal error: The configured groupId is invalid
2021-09-02 14:45:24,806 [org.apache.spark.internal.Logging$class]-[ERROR] Error starting the context, marking it as stopped
org.apache.kafka.common.errors.InvalidGroupIdException: The configured groupId is invalid
	at ... run in separate thread using org.apache.spark.util.ThreadUtils ... ()
	at org.apache.spark.streaming.StreamingContext.liftedTree1$1(StreamingContext.scala:578)
	at org.apache.spark.streaming.StreamingContext.start(StreamingContext.scala:572)
	at org.apache.spark.streaming.api.java.JavaStreamingContext.start(JavaStreamingContext.scala:556)
	at com.apple.streaming.upgrade.news.NewsRealtimeStatSpark.main(NewsRealtimeStatSpark.java:82)
2021-09-02 14:46:08,156 [org.apache.kafka.clients.consumer.internals.AbstractCoordinator$JoinGroupResponseHandler]-[ERROR] [Consumer clientId=consumer-1, groupId=] Attempt to join group failed due to fatal error: The configured groupId is invalid
2021-09-02 14:46:08,159 [org.apache.spark.internal.Logging$class]-[ERROR] Error starting the context, marking it as stopped
org.apache.kafka.common.errors.InvalidGroupIdException: The configured groupId is invalid
	at ... run in separate thread using org.apache.spark.util.ThreadUtils ... ()
	at org.apache.spark.streaming.StreamingContext.liftedTree1$1(StreamingContext.scala:578)
	at org.apache.spark.streaming.StreamingContext.start(StreamingContext.scala:572)
	at org.apache.spark.streaming.api.java.JavaStreamingContext.start(JavaStreamingContext.scala:556)
	at com.apple.streaming.upgrade.news.NewsRealtimeStatSpark.main(NewsRealtimeStatSpark.java:82)
